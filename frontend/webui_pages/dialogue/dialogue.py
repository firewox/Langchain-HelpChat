import streamlit as st
from streamlit_chatbox import *
from datetime import datetime
from configs.project_configs import LOGO_IMG
import asyncio
from backend.servers.chat.openai_chat_services import openai_chat_v1
from typing import List, Dict
from utils.logger import logger
from frontend.api_frontend.api_frontend_chat import api_frontend_chat
from backend.configs.model_config import PROMPT_TEMPLATE_FLAG
from configs.project_configs import ASSISTANT_LOGO_IMG,USER_LOGO_IMG



# ç”¨æˆ·ç¬¬ä¸€æ¬¡è¿›åˆ°é¡µé¢ï¼Œè®¾falg=Trueï¼Œå°†å†å²èŠå¤©è®°å½•æŒ‚è½½åˆ° st.session_state.messages é‡Œ
class dialogue_util:
    FLAG=True
    COUNT=0


# å®ä¾‹åŒ–apiè¯·æ±‚æ¥å£
api_frontend_chat_instance:api_frontend_chat = api_frontend_chat()

# new UI layout
def dialogue_page_v1():
    # ä½¿ç”¨ session_state æ¥å­˜å‚¨å½“å‰çš„é€‰æ‹©
    if 'model_name' not in st.session_state or "model_list" not in st.session_state:
        # ç»™åç«¯å‘è¯·æ±‚ï¼ŒæŸ¥è¯¢å¯ç”¨çš„å¤§æ¨¡å‹
        model_list = api_frontend_chat_instance.get_model_list()
        st.session_state.model_name = model_list[0]
        st.session_state.model_list = [i for i in model_list]
    if "history_name" not in st.session_state or "history_name_list" not in st.session_state:
        # ç»™åç«¯å‘é€è¯·æ±‚ï¼ŒæŒ‚è½½å†å²èŠå¤©è®°å½•çš„åç§°åˆ—è¡¨
        history_name_list = api_frontend_chat_instance.get_history_name_list()
        st.session_state.history_name = history_name_list[0]
        api_frontend_chat_instance.history_name = history_name_list[0]
        st.session_state.history_name_list = [i for i in history_name_list]
        # Initialize chat history
        # # ç»™åç«¯å‘è¯·æ±‚ï¼ŒæŒ‚è½½å†å²èŠå¤©è®°å½•
        messages = api_frontend_chat_instance.get_history_chat(history_name=st.session_state.history_name)
        #st.session_state.messages = messages
    if len(api_frontend_chat_instance.messages)==0:
        # # ç»™åç«¯å‘è¯·æ±‚ï¼ŒæŒ‚è½½å†å²èŠå¤©è®°å½•
        messages = api_frontend_chat_instance.get_history_chat(history_name=st.session_state.history_name)
        #st.session_state.messages = messages

    col1,col2 = st.columns([1,1])
    # col1
    dialogue_util.COUNT+=1
    genre = col1.selectbox(
        ":rainbow[LLM select]",
        (f"{ml}" for ml in st.session_state.model_list),
    )
    api_frontend_chat_instance.model_name = genre
    st.session_state.model_name = genre
    # col2
    col2_placeholder = col2.empty()
    genre2 = col2_placeholder.selectbox(":rainbow[History select]",
                                        (hnl for hnl in st.session_state.history_name_list),)
    if genre2!=st.session_state.history_name:
        api_frontend_chat_instance.history_name = genre2#match.group(1)
        st.session_state.history_name = genre2
        # # ç»™åç«¯å‘è¯·æ±‚ï¼ŒæŒ‚è½½å†å²èŠå¤©è®°å½•
        messages = api_frontend_chat_instance.get_history_chat(history_name=st.session_state.history_name)


    st.title("ğŸ¦œğŸ”— HelpChat App")
    # Display chat messages from history on app rerun
    if len(api_frontend_chat_instance.messages)!=0:
        # TODO å¤„ç† streamlit çš„bugé—®é¢˜ï¼šåœ¨æœ¬è„šæœ¬ä¸­ï¼Œå…³äºmessagesæ•°æ®çš„å¢åŠ å’Œæ˜¾ç¤ºè¢«å¹²æ‰°ï¼Œåç«¯ä¼šå¯¹queryè¿›è¡Œå¤„ç†ï¼šè¿›è¡Œ prompt = query+rag çš„æ“ä½œï¼Œ
        # TODO ä½†æ˜¯å‰ç«¯ streamlité¡µé¢çš„ messagesä¼šè¢«è‡ªåŠ¨æ³¨å…¥ prompt=query+ragã€‚
        #  ä¾‹å¦‚ï¼šæœ¬æ¥çš„queryä¸ºmessages={â€œroleâ€:user,"content":"ä½ å¥½"}ï¼Œç»è¿‡åç«¯å¤„ç†åï¼Œå‰ç«¯çš„messagesè‡ªåŠ¨å˜ä¸º messages={â€œroleâ€:user,"content":"å·²çŸ¥ä¿¡æ¯ï¼šRAGçŸ¥è¯†ï¼Œé—®é¢˜æ˜¯ï¼šä½ å¥½"}
        # TODO ç»è¿‡å¤šç§å°è¯•è§£å†³ï¼Œæš‚æ—¶è§£å†³ä¸äº†
        for i in api_frontend_chat_instance.messages:
            if i.get("role") == "user" and PROMPT_TEMPLATE_FLAG in i.get("content"):
                index = i.get("content").rfind(PROMPT_TEMPLATE_FLAG)
                i["content"] = i.get("content")[index+len(PROMPT_TEMPLATE_FLAG):]
        #st.info(f"st.session_state.messages={st.session_state.messages}")
        for index,message in enumerate(api_frontend_chat_instance.messages):
            if index>=2:
                with st.chat_message(name=message['role'],avatar=":material/face:"):
                    st.markdown(message["content"])

    # Accept user input
    prompt = st.chat_input("æœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿ")
    if prompt:
        # Add user message to chat history
        logger.info(f"\n###queryæµ‹è¯•A={prompt}")
        api_frontend_chat_instance.messages = api_frontend_chat_instance.messages + [{"role": "user", "content": prompt}]
        logger.info(f"\n###queryæµ‹è¯•B={api_frontend_chat_instance.messages}")
        # Display user message in chat message container
        with st.chat_message(name="user",avatar=":material/face:"):
            st.markdown(prompt)

        # Display assistant response in chat message container
        with st.chat_message(name="assistant",avatar=":material/smart_toy:"):
            if len(api_frontend_chat_instance.messages)==0:
                pass
            else:
                # ç»™åç«¯å‘è¯·æ±‚ï¼Œå‘é€æ¶ˆæ¯
                stream = api_frontend_chat_instance.get_chat(model_name=api_frontend_chat_instance.model_name,messages=api_frontend_chat_instance.messages.copy())
                response = st.write_stream(stream)

                # ä¿å­˜è¿”å›çš„èŠå¤©å“åº”
                api_frontend_chat_instance.messages = api_frontend_chat_instance.messages + [{"role":"assistant","content":response}]
                # ç»™åç«¯å‘è¯·æ±‚ï¼Œå®æ—¶ä¿å­˜èŠå¤©è®°å½•
                api_frontend_chat_instance.set_history_chat(messages=api_frontend_chat_instance.messages)






chat_box = ChatBox(
    assistant_avatar=LOGO_IMG
)
def get_messages_history(history_len: int, content_in_expander: bool = False) -> List[Dict]:
    '''
    è¿”å›æ¶ˆæ¯å†å²ã€‚
    content_in_expanderæ§åˆ¶æ˜¯å¦è¿”å›expanderå…ƒç´ ä¸­çš„å†…å®¹ï¼Œä¸€èˆ¬å¯¼å‡ºçš„æ—¶å€™å¯ä»¥é€‰ä¸Šï¼Œä¼ å…¥LLMçš„historyä¸éœ€è¦
    '''

    def filter(msg):
        content = [x for x in msg["elements"] if x._output_method in ["markdown", "text"]]
        if not content_in_expander:
            content = [x for x in content if not x._in_expander]
        content = [x.content for x in content]

        return {
            "role": msg["role"],
            "content": "\n\n".join(content),
        }

    return chat_box.filter_history(history_len=history_len, filter=filter)

def chat_chat():
    pass

def dialogue_page():
    if not chat_box.chat_inited:
        default_model = "glm-4-flash"
        st.toast(
            f"æ¬¢è¿ä½¿ç”¨ [`Langchain-HelpChat`](https://github.com/firewox/Langchain-HelpChat) ! \n\n"
            f"å½“å‰è¿è¡Œçš„æ¨¡å‹`{default_model}`, æ‚¨å¯ä»¥å¼€å§‹æé—®äº†."
        )
        chat_box.init_session()

    chat_box.output_messages()
    dialogue_mode="LLM å¯¹è¯"
    chat_input_placeholder = "è¯·è¾“å…¥å¯¹è¯å†…å®¹ï¼Œæ¢è¡Œè¯·ä½¿ç”¨Shift+Enter "

    messages=[{"role":"user","content":"ä½ æ˜¯è°"},{"role":"assistant","content":"æˆ‘æ˜¯å°åŠ©å¸®æ‰‹"}]
    msg = {"model":"glm-4-flash",
           "messages":messages,
           "temperature":0.7,
           "max_tokens":None,
           "stream":True}
    if prompt := st.chat_input(chat_input_placeholder, key="prompt"):
        chat_box.user_say(prompt)
        messages.append({"role":"user","content":f"{prompt}"})
        if dialogue_mode == "LLM å¯¹è¯":
            chat_box.ai_say("æ­£åœ¨æ€è€ƒ...")

            def stream_chat(chat_box=chat_box):
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                async def stream_chat1(chat_box=chat_box):
                    text = ""
                    # è·å–å¼‚æ­¥ç”Ÿæˆå™¨
                    response_generator = await openai_chat_v1(msg=msg)
                    # ä½¿ç”¨ async for éå†ç”Ÿæˆå™¨
                    async for chunk in response_generator:
                        text += chunk
                        chat_box.update_msg(text)
                loop.run_until_complete(stream_chat1(chat_box=chat_box))
                loop.close()
            stream_chat(chat_box=chat_box)
            #logger.info(f"chat_box.context={text}")
            #chat_box.update_msg(streaming=False)  # æ›´æ–°æœ€ç»ˆçš„å­—ç¬¦ä¸²ï¼Œå»é™¤å…‰æ ‡

    now = datetime.now()
    with st.sidebar:

        cols = st.columns(2)
        export_btn = cols[0]
        if cols[1].button(
                "æ¸…ç©ºå¯¹è¯",
                use_container_width=True,
        ):
            chat_box.reset_history()
            st.experimental_rerun()

    export_btn.download_button(
        "å¯¼å‡ºè®°å½•",
        "".join(chat_box.export2md()),
        file_name=f"{now:%Y-%m-%d %H.%M}_å¯¹è¯è®°å½•.md",
        mime="text/markdown",
        use_container_width=True,
    )